{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e25d4f",
   "metadata": {},
   "source": [
    "# CV Ranking Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f65f8",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e5b509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T01:01:27.923761Z",
     "start_time": "2024-08-30T01:01:27.895581Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import fitz\n",
    "import re\n",
    "class TextExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.directory = None\n",
    "        self.pdf_path = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # X is expected to be a dictionary with 'directory' or 'pdf_path'\n",
    "        if 'directory' in X:\n",
    "            self.directory = X['directory']\n",
    "        elif 'pdf_path' in X:\n",
    "            self.pdf_path = X['pdf_path']\n",
    "        else:\n",
    "            raise ValueError(\"Input X must contain either 'directory' or 'pdf_path'.\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        if self.pdf_path:\n",
    "            # Return a dictionary with a single entry for the single PDF\n",
    "            return {self.pdf_path: self.extract_text_from_pdf(self.pdf_path)}\n",
    "        elif self.directory:\n",
    "            # Return a dictionary of texts extracted from all PDFs in the directory\n",
    "            return self.load_documents(self.directory)\n",
    "        else:\n",
    "            raise ValueError(\"Either directory or pdf_path must be provided.\")\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_path):\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        extracted_text = ''\n",
    "        for page_number in range(len(pdf_document)):\n",
    "            page = pdf_document.load_page(page_number)\n",
    "            text = page.get_text()\n",
    "            extracted_text += text + \"\\n\\n\"\n",
    "        return extracted_text\n",
    "\n",
    "    def load_documents(self, directory):\n",
    "        documents = {}\n",
    "        for filename in os.listdir(directory):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            documents[filename] = self.extract_text_from_pdf(file_path)\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0250edcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T01:01:31.013835Z",
     "start_time": "2024-08-30T01:01:30.994993Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, document_dict):\n",
    "        if not isinstance(document_dict, dict):\n",
    "            raise ValueError(\"Input must be a dictionary where keys are filenames and values are texts.\")\n",
    "        return {key: self.clean_text(text) for key, text in document_dict.items()}\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = re.sub(r'\\n+', ' ', text)\n",
    "        text = re.sub(r'\\s+([.,!?;:])', r'\\1', text)\n",
    "        text = re.sub(r'\\s*[\\u2022\\u25AA\\u25AB]\\s*', ' ', text)\n",
    "        text = re.sub(r'\\s*-\\s*', ' - ', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.lower() \n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb56568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T01:01:35.308482Z",
     "start_time": "2024-08-30T01:01:35.044927Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the pipeline with the custom transformers\n",
    "pipeline = Pipeline([\n",
    "    ('text_extractor', TextExtractor()),\n",
    "    ('text_cleaner', TextCleaner())\n",
    "])\n",
    "\n",
    "# Example of fitting with a directory path\n",
    "transformed_cvs = pipeline.fit_transform({'directory': \"C:/Users/User/LLM/CVs/\"})\n",
    "\n",
    "# Example of fitting with a single PDF path\n",
    "transformed_job = list(pipeline.fit_transform({'pdf_path': r\"C:/Users/User/LLM/Job_Desc/Podcaster Job Ad.pdf\"}).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9497e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T13:51:25.194757Z",
     "start_time": "2024-08-28T13:51:25.187234Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job description: are you a finance enthusiast with a knack for storytelling? do you have a passion for educating and inspiring others when it comes to personal finance, investing, and financial literacy? if so, we have an exciting opportunity for you! pan finance is seeking a talented finance podcaster to join our team. responsibilities: podcast content creation: produce engaging and informative podcast episodes covering various finance topics, from budgeting and investing to financial planning and market trends. scriptwriting: research and develop well - structured scripts for podcast episodes, ensuring content is clear, accurate, and tailored to our target audience. host and co - host: host podcast episodes, interview guests, and co - host discussions to provide valuable insights and perspectives on finance - related subjects. editing and post - production: oversee the editing and post - production process of podcast episodes to ensure high - quality content and a seamless listener experience. audience engagement: interact with our audience by responding to comments, questions, and feedback, fostering a sense of community and trust among listeners. stay informed: keep up - to - date with the latest financial news, trends, and developments to provide relevant and timely content. qualifications: passion for finance: a genuine interest and passion for finance, investing, and financial literacy. podcasting experience: previous experience in podcasting, including scriptwriting and hosting, is a plus. excellent communication: strong verbal and written communication skills. financial knowledge: a solid understanding of financial concepts and the ability to simplify complex topics for a general audience. tech savvy: familiarity with podcast recording and editing tools is a bonus. creativity: ability to think creatively and bring fresh ideas to the podcast content. team player: collaborative and willing to work closely with our content and production teams.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc8a048",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:32:37.676462Z",
     "start_time": "2024-08-28T15:31:02.098021Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Podcast Host_Producer Damien  Swaby  (1).pdf: 0.1992\n",
      "Violetta_Nadbitova_CV-1.pdf: 0.1339\n",
      "Kindra Keener 2024 CV.pdf: 0.0492\n",
      "CV Martin Kriletich 2024.pdf: 0.0479\n",
      "Benjamin_Salebaigi.pdf: 0.0243\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Tokenize and remove punctuation and stopwords\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Example cleaned CVs and job description\n",
    "cleaned_cvs = {name: clean_text(text) for name, text in transformed_cvs.items()}\n",
    "cleaned_job = clean_text(transformed_job[0])\n",
    "\n",
    "# Prepare texts for vectorization\n",
    "texts = list(cleaned_cvs.values()) + [cleaned_job]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Calculate similarity scores\n",
    "cv_tfidf_matrix = tfidf_matrix[:-1]\n",
    "job_tfidf_vector = tfidf_matrix[-1]\n",
    "similarity_scores = cosine_similarity(cv_tfidf_matrix, job_tfidf_vector.reshape(1, -1))\n",
    "\n",
    "# Create a dictionary of CV names and their relevance scores\n",
    "relevance_scores = {cv_name: similarity_scores[i][0] for i, cv_name in enumerate(cleaned_cvs.keys())}\n",
    "\n",
    "# Sort CVs based on relevance scores\n",
    "sorted_cvs = sorted(relevance_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Print sorted CVs with their relevance scores\n",
    "for cv_name, score in sorted_cvs:\n",
    "    print(f'{cv_name}: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99dae8",
   "metadata": {},
   "source": [
    "## Data Preparation for Model fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345fbe15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:33:24.402073Z",
     "start_time": "2024-08-28T15:33:23.251948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_name</th>\n",
       "      <th>cv_text</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benjamin_Salebaigi.pdf</td>\n",
       "      <td>benjamin salebaigi 2011 - 70 temperance street...</td>\n",
       "      <td>job description: are you a finance enthusiast ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CV Martin Kriletich 2024.pdf</td>\n",
       "      <td>martin kriletich global business manager work ...</td>\n",
       "      <td>job description: are you a finance enthusiast ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV Podcast Host_Producer Damien  Swaby  (1).pdf</td>\n",
       "      <td>07984921407 lmmakerswaby@hotmail.com london, n...</td>\n",
       "      <td>job description: are you a finance enthusiast ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kindra Keener 2024 CV.pdf</td>\n",
       "      <td>contact education (917) 288 - 5445 phone kindr...</td>\n",
       "      <td>job description: are you a finance enthusiast ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Violetta_Nadbitova_CV-1.pdf</td>\n",
       "      <td>violetta nadbitova 07725003082 | venadbitova@g...</td>\n",
       "      <td>job description: are you a finance enthusiast ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cv_name  \\\n",
       "0                           Benjamin_Salebaigi.pdf   \n",
       "1                     CV Martin Kriletich 2024.pdf   \n",
       "2  CV Podcast Host_Producer Damien  Swaby  (1).pdf   \n",
       "3                        Kindra Keener 2024 CV.pdf   \n",
       "4                      Violetta_Nadbitova_CV-1.pdf   \n",
       "\n",
       "                                             cv_text  \\\n",
       "0  benjamin salebaigi 2011 - 70 temperance street...   \n",
       "1  martin kriletich global business manager work ...   \n",
       "2  07984921407 lmmakerswaby@hotmail.com london, n...   \n",
       "3  contact education (917) 288 - 5445 phone kindr...   \n",
       "4  violetta nadbitova 07725003082 | venadbitova@g...   \n",
       "\n",
       "                                     job_description  label  \n",
       "0  job description: are you a finance enthusiast ...      0  \n",
       "1  job description: are you a finance enthusiast ...      0  \n",
       "2  job description: are you a finance enthusiast ...      1  \n",
       "3  job description: are you a finance enthusiast ...      0  \n",
       "4  job description: are you a finance enthusiast ...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example similarity scores\n",
    "similarity_scores = {\n",
    "    'CV Podcast Host_Producer Damien  Swaby  (1).pdf': 0.1992,\n",
    "    \"Violetta_Nadbitova_CV-1.pdf\": 0.1339,\n",
    "    \"Kindra Keener 2024 CV.pdf\": 0.0492,\n",
    "    \"CV Martin Kriletich 2024.pdf\": 0.0479,\n",
    "    \"Benjamin_Salebaigi.pdf\": 0.0243\n",
    "}\n",
    "\n",
    "# Define a threshold to classify CVs as relevant or not\n",
    "threshold = 0.1\n",
    "\n",
    "# Prepare data using processed CVs and job descriptions\n",
    "data = []\n",
    "for cv_name in transformed_cvs.keys():\n",
    "    cv_text = transformed_cvs[cv_name]  # Get CV text from transformed_cvs\n",
    "    job_description = transformed_job[0]  # Assuming transformed_job is a list with job description\n",
    "    \n",
    "    # Get the similarity score for the CV\n",
    "    score = similarity_scores[cv_name]\n",
    "    \n",
    "    # Create label based on the threshold\n",
    "    label = 1 if score > threshold else 0\n",
    "    \n",
    "    data.append({\n",
    "        'cv_name': cv_name,\n",
    "        \"cv_text\": cv_text,\n",
    "        \"job_description\": job_description,\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Output the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d5c687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:33:59.940148Z",
     "start_time": "2024-08-28T15:33:42.439683Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Convert DataFrame to Dataset\n",
    "data = {\n",
    "    \"cv_text\": df[\"cv_text\"].tolist(),\n",
    "    \"job_description\": df[\"job_description\"].tolist(),\n",
    "    \"label\": df[\"label\"].tolist()\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d1f86e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:28:04.726260Z",
     "start_time": "2024-08-28T14:28:02.152727Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7802b55750464e43bee10900638d20e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['cv_text'], examples['job_description'], \n",
    "        padding='max_length', truncation=True\n",
    "    )\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "data_list = tokenized_dataset.to_pandas()\n",
    "train_df, eval_df = train_test_split(data_list, test_size=0.4)\n",
    "\n",
    "# Convert DataFrames back to Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c26dc76",
   "metadata": {},
   "source": [
    "## Fine Tuning Language model with the provided dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a55bcbb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:58:04.444300Z",
     "start_time": "2024-08-28T14:46:18.161614Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 11:24, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.189684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.191802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.193943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.168458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.134089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.112140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.097239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.086043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.077286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.070341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.064467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.059602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.055604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.052120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.049642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.048032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.047021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.046127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.045498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.045254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=40, training_loss=0.11552071571350098, metrics={'train_runtime': 704.7159, 'train_samples_per_second': 0.085, 'train_steps_per_second': 0.057, 'total_flos': 15786663321600.0, 'train_loss': 0.11552071571350098, 'epoch': 20.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.09,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset  # Include eval_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b033eb",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68aa5431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T02:11:49.818764Z",
     "start_time": "2024-08-28T02:11:49.806954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Benjamin_Salebaigi.pdf', 'CV Martin Kriletich 2024.pdf', 'CV Podcast Host_Producer Damien  Swaby  (1).pdf', 'Kindra Keener 2024 CV.pdf', 'Violetta_Nadbitova_CV-1.pdf'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_cvs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5be38781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:59:26.306316Z",
     "start_time": "2024-08-28T14:59:20.679145Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "eval_loss: 0.0453\n",
      "eval_runtime: 5.6043\n",
      "eval_samples_per_second: 0.3570\n",
      "eval_steps_per_second: 0.1780\n",
      "epoch: 20.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "evaluation_metrics = trainer.evaluate()\n",
    "\n",
    "# Print out the evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "for key, value in evaluation_metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efeec4",
   "metadata": {},
   "source": [
    "## Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c50e6adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:03:37.489794Z",
     "start_time": "2024-08-28T15:03:36.718216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine-tuned-model\\\\tokenizer_config.json',\n",
       " './fine-tuned-model\\\\special_tokens_map.json',\n",
       " './fine-tuned-model\\\\vocab.txt',\n",
       " './fine-tuned-model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the fine-tuned model and tokenizer\n",
    "model.save_pretrained('./fine-tuned-model')\n",
    "tokenizer.save_pretrained('./fine-tuned-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4787e05",
   "metadata": {},
   "source": [
    "## Loading the model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b962d0c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T06:09:31.521328Z",
     "start_time": "2024-08-29T06:09:24.746816Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./fine-tuned-model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./fine-tuned-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0647720",
   "metadata": {},
   "source": [
    "## Testing model with the trained Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9e695d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:36:17.497736Z",
     "start_time": "2024-08-28T15:36:10.495451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Violetta_Nadbitova_CV-1.pdf with score 0.8981\n",
      "Rank 2: CV Podcast Host_Producer Damien  Swaby  (1).pdf with score 0.8972\n",
      "Rank 3: CV Martin Kriletich 2024.pdf with score 0.8954\n",
      "Rank 4: Benjamin_Salebaigi.pdf with score 0.8922\n",
      "Rank 5: Kindra Keener 2024 CV.pdf with score 0.8919\n"
     ]
    }
   ],
   "source": [
    "input_texts = [f\"{cv} [SEP] {transformed_job[0]}\" for cv in transformed_cvs]\n",
    "tokenized_inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Get model predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_inputs)\n",
    "    predictions = torch.softmax(outputs.logits, dim=1)[:, 1]  # Probability of being relevant\n",
    "\n",
    "# Rank CVs based on predictions\n",
    "ranked_cvs = sorted(zip(transformed_cvs.keys(), predictions.numpy()), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Output ranked CVs\n",
    "for i, (cv, score) in enumerate(ranked_cvs):\n",
    "    print(f\"Rank {i+1}: {cv} with score {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0120a4c",
   "metadata": {},
   "source": [
    "## Testing Model with new CVs and Job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af0d084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T06:10:55.316876Z",
     "start_time": "2024-08-29T06:10:55.116827Z"
    }
   },
   "outputs": [],
   "source": [
    "new_cvs = pipeline.fit_transform({'directory': \"C:/Users/User/LLM/Test_cv/\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74b6b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T06:11:41.622784Z",
     "start_time": "2024-08-29T06:11:41.593481Z"
    }
   },
   "outputs": [],
   "source": [
    "new_job = list(pipeline.fit_transform({'pdf_path': r\"C:/Users/User/LLM/Job_Desc/Job_desc.pdf\"}).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e8bd52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T06:11:45.059889Z",
     "start_time": "2024-08-29T06:11:45.044432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Johanson_Onyegbula_CV.pdf': 'onyegbula, johanson chibuike +2348139378788 | johansononyegbula20@gmail.com | www.linkedin.com/in/johanson - onyegbula - 6484bb76/ education university of lagos (unilag), nigeria 2014 2019 bachelor of science (bsc.) in surveying and geoinformatics first class (honours) 4.85/5.00 b.sc. thesis: quality assessment of 20m spot dem using gps ground control points for lagos state, nigeria. conference presentations university of lagos, nigeria october, 2019 alademomi, a.s, okolie, c.j, ojegbile, b.m., daramola, o.e., onyegbula, j.c. and adepo, r.o. (2019). modelling and analysis of environmental noise levels within the university of lagos main campus. presented at the faculty of engineering international conference, university of lagos, october 15 - 18, 2019. doi: 10.13140/rg.2.2.32447.46240 nwilo, p.c., okolie, c.j., onyegbula, j.c., abolaji, o.e., orji, m.j. and daramola, o.e. (2019). validation of the 20 - metre spot dem using ground control points from lagos and abuja, nigeria. presented at the faculty of engineering international conference, university of lagos, october 15 - 18, 2019. doi: 10.13140/rg.2.2.31608.60165 peer - reviewed publications nwilo, p.c., okolie, c.j., onyegbula, j.c., abolaji, o.e., orji, m.j., daramola, o.e. and arungwa, i.d. (2020). vertical accuracy assessment of 20 - metre spot dem using ground control points from lagos and abuja, nigeria. published in the journal of engineering research, nigeria http://ujh.unilag.edu.ng/index.php/jer/article/view/997 alademomi, a.s, okolie, c.j, ojegbile, b.m., daramola, o.e., onyegbula, j.c., adepo, r.o., and ademeno, w. (2020). spatial and statistical analysis of environmental noise levels in a university campus. accepted in the journal of engineering research, oman. vol. 17, no. 2, 75 - 88. doi: 10.24200/tjer.vol17iss2pp75 - 88. nwilo, p.c., onyegbula, j.c., okolie, c.j., daramola, o.e. abolaji, o.e. and arungwa, i.d. (2020). quality assessment of the 20m spot dem in nigeria. submitted to the journal of geo - spatial information science. work experience lagos waste management authority, national youth service corps (nysc) project unit engineer september 2020 date supervised civil engineering renovations and in - situ construction activities, with documentations prepared. hamoye ai labs data science internship (remote) july 2020 december 2020 pre - processed data for analysis with data cleaning and wrangling operations. predicted trends and analyzed data using machine learning regression models with python. classified data and optimized performance of classifiers with machine learning classification models. integrated software services limited information technology intern december 2019 february 2020 designed front end of proposals for web - based business applications using vaadin in java. developed the sql database structure and java program for a database synchronization project. geo - solutions team, shell nigeria exploration and production company geomatics intern july 2018 december 2018 analyzed and positioned sampling locations for a proposed environmental impact assessment. facilitated planning of proposed offshore facilities by conducting a hazard analysis of existing facilities. validated coordinates from drilling location requests and quality control of geodetic data. developed a matlab program which eased meteorological and oceanographic data analysis. updated company s spud can database for sewop and rig moves and created maps with arcgis. teaching experience university of lagos academic tutor march 2015 october 2019 tutored over 60 students in various courses and software trainings. mentored students with low academic standings, which led to drastic improvements in their performances. provided academic materials and past questions for students of every level in my department. shell nigeria exploration and production company (snepco) intern s tutor august 2018 december 2018 tutored 3 other interns on the basic use of arcgis for creating geodatabases, feature classes and map - making, and the use of matlab for scripting. volunteer experience nysc lagos camp march 2020 volleyball coach coached my platoon s female volleyball team for inter - platoon competitions, and led them to victory. head of hse committee feb 2018 april 2018 university of lagos facilitated hse training programs with health, safety and environment (hse) officers from deeprimex consulting for three levels of certified hse trainings for over 50 students and a few interested non - students. awards / honours fugro undergraduate scholarship (2019). spdc annual undergraduate scholarship (2016 2019). chevron annual undergraduate scholarship (2016 2019). annual endowment scholarship for first class students, university of lagos (2016 2019). academic excellence award, surveying and geoinformatics, university of lagos (2018). winner of pa adekunle annual essay competition (2016). best student 2nd year surveying and geoinformatics student, university of lagos (2016). professional development and certifications 2020 deep learning specialization, deeplearning.ai (via coursera). responsive website development & design specialization, university of london (via coursera). basics of web development & coding specialization, university of michigan (via coursera). machine learning, stanford university (via coursera). 2019 basic 3d laser scanning and processing, young surveyors network, lagos. 2018 hse trainings for levels 1, 2 and 3, deeprimex consulting. 2015 basic gis, geores limited. leadership experience 2018 2020 unit s secretary, catholic youth organisation of nigeria. 2018 2020 educational arm coordinator, catholic youth organisation of nigeria. 2019 electoral committee officer: faculty of engineering, university of lagos. 2018 vice president: department of surveying and geoinformatics, university of lagos. 2016 2017 class representative: department of surveying and geoinformatics, university of lagos. 2015 assistant class representative: department of surveying and geoinformatics, university of lagos. additional information technical skills python, matlab, java, arcgis, html, css, envi, javascript, mysql, php, visual basic and microsoft office packages. professional membership young surveyors network (ysn), lagos. organizational skills excellent numerical, analytical and documentation skills; excellent verbal and written communication skills; quick adaptability to new technologies.',\n",
       " 'MUTALIB Tunde Lawal; CV.pdf': 'lawal mutalib tunde +2348103525932 6 michael akinola, lawalmutalib2016@gmail.com onimangoro area, ikeja, lagos state nigeria education bsc usmanu danfodiyo university, sokoto, nigeria, accounting 2016 - 2021 best top 2% of class best student with 87.2% score/gpa of 4.36 on a 5.00 scale overall best student in research thesis (distinction) fellowship award by suffolk university, boston, usa ($20,000) research experience final account department national youths service corps (nysc) ministry of finance, budget, and planning (nasarawa state government) 2022 - 2023 reporting and management tasks accounting discrepancies and other financial related issues reviewed financial paperwork and procedures and make appropriate changes carried out research activities within the department research assistant/marketer bram haven consulting, usmanu danfodiyo university mini - mart, sokoto 2019 - 2021 conducted research in human resource and education collected data and information needed for theses and dissertations participated in field work and survey for research purposes created awareness about the consultancy within the faculty/department research fellowship nertherlands education group (stichting libertas international) june, 2020 - dec. 2020 conducted market research contacted various organization in order to establish new contracts for the nertherlands education group spreading information about the nertherlands education group prepared small research assignments worked with social media fixed term intern contract workrub int. limited nov. 2020 - feb. 2021 analyzed american audited company financial statements comparative analysis of five years financial statements provided review and suggestions for possible development prepared small research assignments with the representative teaching experience usmanu danfodiyo university, sokoto, nigeria 2019 - 2021 student instructor, act 499 (research thesis) assisted students in a critical review of scientific literatures collected data and information necessary for data analysis edited and overviewed an undergraduate thesis delivered an educational session related to extraction of literature review omolabake nursery and primary school, nigeria 2018 - 2019 instructor, business studies; english language, and mathematics taught business studies; english language, and mathematics participated in congress planning and management of school counselled students at proper time graded term papers; final examination, and tutorial participation almarkaznur nursery and primary school, nigeria 2015 - 2016 instructor, business studies and mathematics taught business studies and mathematics to grade 4; 5, and 6 planned and facilitated assembly for students marked; prepared, and submitted students results designed and delivered educational session in large - medium format publications chapter in book emerging trends, issues and challenges in india economy , in chapter 5 of emerging india in 21st century (with special reference to society, economy, women and politics) . department of political science of jvmgrr college, charkhi dadri (haryana), india, february 2020. this book was co - authored among others by with dr. meenakshi bansal undergraduate thesis oil and gas companies in nigeria s 21st century: an analysis of factors inhibiting their growth and operational performance (bsc thesis) international anthologies of engish literary works and short stories: nostagia - co - authored with dr. ratan ghosh, musings - co - authored with sindhu nandakumar, williamsji maveli, heart upon sleeve - co - authored with dr. ashish kumar gupta, and scarlet anatomy published in nigeria and india. professional development training conferences and workshop attended with dates digital marketing agency training organized by skyhub nigeria at auditorioum, bureau of information, communication and technology (bict), lafia, nasarawa state. 2nd june, 2022. 3rd annual faculty of management sciences conference on fiscal discipline, economic diversification and management of the budget crisis in nigeria at auditorium, usmanu danfodiyo university, sokoto permanent site. 18th - 20th june, 2019. first quarter 2021 navigating energy transition and the imperatives of university - industry collaboration at auditorium, main campus, usmanu danfodiyo university, sokoto. 27th january, 2021 research proposal writing and grant management. university auditorium, main campus. attended the workshop virtually on 8th march, 2021 5th international conference on management studies and social sciences (5th masos). live stream conference presentation of research synergy foundation, bandung, west java, and indonesia. 29th june, 2020. lppm upn veteran yogyakarta international conference series 2020: economic and business series (ebs), indonesia.27th 28th october, 2020|virtual conference seminars/webinars the international program of ambassadors of sustainability which comprises introduction on sustainability and sdg s, economic sustainability, environmental sustainability, governance and leadership organized by dr. wesam al madhoun of faculty of civil engineering and built environment, universiti tun hussein onn malaysia (uthm). 10th - 14th august, 2020 the international program of micro pollutant research centre (uthm) on water treatment, desalination technology, and sustainability . professional affiliations associate member, international environmental forum, switzerland member, world economics association (wea) member, impact youth sustainability (iys), ilorin, nigeria professional service member, nigeria universities accounting students association of usmanu danfodiyo university, sokoto, sokoto state, nigeria 2016 - 2021 financial secretary, faculty of management sciences students association, usmanu danfodiyo university, sokoto, sokoto state, nigeria. 2019 - 2021 community service assistant state director, impact youth sustainability, ilorin, 2020 - present volunteer accounting department, usmanu danfodiyo university, sokoto 2016 - 2021 teaching extra - classes for an average undergraduate students voluntarily languages english: official language, distinguished levels in listening, speaking, reading, and writing. yoruba: nigerian language skills and competences ms word; basic microsoft excel, basic accounting sage, power point presentation, and proficient in developing thesis, research articles, survey design, field work, and analysis (contextual and empirical) other skills analytical skill; organizational skill, problem solving skill, interpersonal skill, reporting skill, communication, reading, writing, and listening skill references available upon request',\n",
       " 'Taofik CV RPI.pdf': 'taofik ahmed suleiman +2348131052106 | eika ohizenyi - aboze st., nigeria | suleimantaofik6@gmail.com | linkedin.com/in/taofik - ahmed - suleiman - 149ab914b objective to obtain a phd in in biomedical engineering and achieve professional proficiency, while enhancing independent research, and teaching/administrative skills. research interest: orthopedic and tissue regeneration, soft tissue, biomaterials, cancer and stem cell biology, drug discovery technical skills: medical device repair, cell culture, microscopy, python, bioinformatics, matlab, ms office tools, data analysis education university of ilorin (unilorin), kwara state, nigeria oct. 2015 aug. 2021 beng in biomedical engineering (first class honours - 4.68/5.00) relevant courses (grades): molecular and cellular biology (a), nanomedicine (a), biomaterials (a), medical imaging system (a), biomechanics (a), general anatomy (a), human physiology (a), engineering mathematics (a), electronics (a), and thermodynamics (a) kogi state polytechnics (ksp), lokoja, kogi state, nigeria dec. 2013 - sept. 2015 ond in science laboratory technology (cgpa: 3.35/4.00, rank: 1 out of 226 students) relevant courses (grades): inorganic chemistry (a), physical chemistry (a), organic chemistry (ab), biochemistry (ab), microbiology (ab), genetics (ab), electricity and magnetism (ab), optics and waves (a), calculus (ab), and algebraic for science (a) publications and presentations pan african research group, biotechnological models for enhanced drug discovery, ongoing research y. k. ahmed, t. a. suleiman, a. m. ibrahim, n. a. danmusa, and h. d. yusuff, inexpensive collapsible vibration plate for whole - body exercise and physiotherapy in low resource settings, link to abstract y. k. ahmed, n. a. danmusa, k. a. salahudeen, t. a. suleiman, and h. d. yusuff, design and development of an eye and mobile application controlled wheelchair for totally and partially paralyzed patients, link to abstract national association of biomedical engineering students 2021 workshop, diving into technology hotspots: the role of data science in bioengineering , by t. a. suleiman, department of biomedical engineering, university of ilorin, april 23rd, 2021 nanomedicine (bme505) presentation 2020, applications of micelles and dendrimers in drug delivery , by t. a. suleiman, department of biomedical engineering, university of ilorin, jan. 8th, 2020. research and teaching experience research assistant: pan african research group, parg april 2021 - present o wrote literature review on quality and design implementation in biotechnological drug discovery o wrote literature review on proteins and genes as targets for drug discovery undergraduate research assistant: biomedical engineering, unilorin oct. 2019 - july 2021 o assisted academic staff in the department of biomedical engineering in research and administrative work o wrote research proposals, analyzed project data, and reported findings. achievement: as the lead investigator, i led a team in designing the following: o inexpensive collapsible vibration plate for whole - body exercise and physiotherapy in low resource settings o an eye and mobile application controlled wheelchair for totally and partially paralyzed patients high school teacher: new hope college, ilorin, nigeria nov. 2020 - july 2021 o taught physics and further mathematics to senior classes 1, 2 & 3. o provided assessments and graded students on the course taught and practical sessions head tutor: department of biomedical engineering, university of ilorin, ilorin nov. 2017 feb. 2020 o organized and conducted tutorial classes on core biomedical engineering courses across all levels. o assisted in compiling past questions and simplifying complex courses during tutorial classes for easy understanding. industrial experience graduate intern: biomedical department, nisa premier hospital, abuja, nigeria sept. 2021 - present key responsibilities and trainings: o supporting patient diagnosis and treatment by installing, calibrating and repairing medical devices o collecting, examining, and testing tissue samples to better understand diseases pathophysiology student intern: nisa premier hospital, abuja, nigeria mar. 2019 - dec. 2019 o repaired medical devices at the biomedical department o maintained medical imaging equipment and installation such as ultrasound, digital x - rays and mri student intern: university of ilorin teaching hospital (uith), kwara state, nigeria aug. 2018 - dec. 2018 o installed, calibrated, repaired and tested medical equipment at the biomedical workshop industrial training: sauki medical diagnostics, kogi state, nigeria dec. 2014 - feb. 2015 o assisted in identifying microorganisms, such as bacteria, that are found in blood or skin o assisted in performing cell culture and sensitivity testing for effective treatment of various diseases. o examined patients for malaria, hiv antigens, and typhoid fever using rapid test kits leadership responsibilities / experiences class representative: biomedical engineering students, class of 2021 2017 - 2021 vice president: dareword students association (dsa), unilorin 2019 - 2021 president: national association of ebira students (naes), unilorin chapter 2019 - 2021 team leader: undergraduate research work, department of biomedical engineering 2019 - 2021 academic excellence/technical chair: national society of black engineers (nsbe), unilorin 2017 - 2019 secretary - general, national association of biomedical engineering students (nabmes), unilorin 2017 - 2018 awards / honours university of ilorin undergraduate scholarship award for the best student in biomedical engineering 2016 - 2021 first class honours award in biomedical engineering, university of ilorin 2021 academic excellence and altruistic leadership award, naes unilorin chapter 2021 best presenter and researcher award, academic elite of ebiraland (aee) annual competition 2019 academic excellence award, nsbe unilorin 2018 best graduating student in science laboratory technology, ksp 2015 professional development and certifications introduction to the biology of cancer, johns hopkins university, coursera 2021 biologic hallmarks of cancer, molecular biology, risk factors, treatment options, imaging and staging techniques fundamentals of immunology, rice university, coursera 2021 innate & adaptive immunity; b & t cells, antigens, antibodies, immunoglobulin receptors, myeloid & lymphoid cells programming for everybody (python), university of michigan, coursera 2020 introduction to python, data type, variables, python tools such as functions and loops bioinformatics for beginners, university of california, san diego, coursera 2020 bioinformatics, bioinformatics algorithms, biology and python programming volunteering and community service member and media team volunteer for oneafricanchild foundation 2021 volunteer and member of young african leaders initiatives, yali network 2021 logistic team, oladepo timilehin foundation - empowering youth and community 2021 dsa mentor for newly admitted undergraduate students of the university of ilorin 2017 - 2021 participated in the nsbe impact 50 lives community outreach, kwara, nigeria 2019 professional membership / affiliations nigerian society of engineers (nse) 2021 american society of quality (asq) 2020 national society of black engineers (nsbe) 2017 national association of biomedical engineering students (nabmes), unilorin 2015 - 2021 welcome to my e - portfolio https://suleimantaofik6.wixsite.com/einstein to learn more about my skills, experiences, and current projects.',\n",
       " 'Yussuf-Resume.pdf': \"yussuf laaro olamilekan araromi, okolowo, ilorin, kwara, nigeria. email | github | linkedin education university of ilorin, kwara state, nigeria november 2018 august 2024 degree: bachelor of engineering in water resources and environmental engineering. cumulative gpa: 4.81/5.0 (ranked highest in the department) skills programming language and machine learning framework: python, scikit - learn, & tensorflow. data analysis and visualization: python, excel, mysql, matplotlib, seaborn, & plotly. git and github (version control) additional skill: analytical thinking, problem - solving, attention to detail, effective communication skills for collaboration with cross - functional teams, time management and presentation skill. work experience hamoye junior data engineer july october 2023 conducted introductory research on fluentd for log data collection and created documentation. conducted research on generative ai and prepared an introductory note as a valuable resource for the company's internship program as a course. hamoye data science intern november 2022 march 2023 led team isomap of about 10 interns in developing a predictive model for black friday purchases. built a next - word prediction model with the team vizpy as the assistant team lead. came 2nd out of about 500 interns in two different stages of the internship s quiz and coding challenge. projects simple business performance analysis system may 2024 developed a business performance analysis system using mysql and python to simulate and analyze sales data, enhancing strategic decision - making with real - time business intelligence. implemented dynamic data visualization and management features to track sales performance, identify trends, and ensure data integrity within a mysql database framework. sentiment analysis for financial news april 2024 developed a sentiment analysis model to classify financial news sentiments, improving market insight. built a streamlit web interface for real - time headline analysis with advanced text preprocessing. fraud detection in transaction april 2024 developed a randomforestclassifier to identify fraudulent transactions using advanced feature engineering and smote for class imbalance, enhancing model accuracy. automated data preprocessing from json - formatted text files, significantly improving data quality and readiness for machine learning analysis. waste image classifier august 2023 implemented and trained a vgg16 - based image classifier using opencv and transfer learning, achieving 88.66% accuracy in classifying waste as organic or recyclable. deployed the model on streamlit to create a user - friendly, real - time interface for efficient waste classification. movies recommender system july 2023 developed a movies recommender system in python utilizing scikit - learn and pandas to implement algorithms like popularity - based, content - based, and collaborative filtering. engineered movie features and used numpy and scikit - learn for vector transformations, employing cosine similarity to provide personalized movie recommendations. email spam classifier march 2023 applied nlp techniques using nltk and scikit - learn for email text preprocessing, feature extraction, and model training. conducted extensive data cleaning, including handling attachments, removing html tags, and extracting text from emails to improve classification performance. certifications introduction to generative ai april 2024 issuing organization: coursera introduction to large language model april 2024 issuing organization: coursera data science internship program march 2023 issuing organization: hamoye.com advanced learning algorithm january 2023 issuing organization: coursera data analysis with python: zero to pandas september 2022 issuing organization: jovian supervised machine learning: regression and classification august 2022 issuing organization: coursera excel fundamental for data analysis june 2022 issuing organization: coursera\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce68dc01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T06:12:27.887167Z",
     "start_time": "2024-08-29T06:12:27.873115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"job title: junior data engineer location: araromi, okolowo, ilorin, kwara, nigeria company overview: we are a dynamic and innovative company focused on leveraging data to drive business success. we are committed to fostering a collaborative environment where creative minds can thrive and make impactful contributions. join us as we shape the future of data - driven decision - making. job description: we are seeking a highly skilled and motivated junior data engineer to join our team. the ideal candidate will have a strong background in data engineering, data science, and machine learning, with experience in developing and deploying data - driven solutions. the candidate will work closely with cross - functional teams to ensure the smooth and efficient flow of data within the organization. key responsibilities: data integration and management: conduct research and implementation of data collection tools, such as fluentd, to streamline log data collection and integration processes. generative ai research: conduct research on generative ai technologies and create comprehensive documentation and training materials for internal use. data engineering: develop and maintain data pipelines, ensuring data quality, integrity, and availability for analysis. collaboration and leadership: lead and collaborate with teams in developing predictive models, such as those for customer behavior analysis and fraud detection. real - time data analysis: design and implement systems for real - time data analysis and visualization, enhancing strategic decision - making processes. qualifications: educational background: bachelor's degree in water resources and environmental engineering or a related field, with a strong academic record (cumulative gpa of 4.81/5.0). technical skills: proficiency in python, scikit - learn, tensorflow, mysql, and data visualization tools such as matplotlib, seaborn, and plotly. version control: strong experience with git and github for version control and collaboration. analytical skills: excellent problem - solving abilities, attention to detail, and the ability to analyze complex datasets to derive actionable insights. communication skills: effective communication skills, both written and verbal, for collaborating with cross - functional teams and presenting data - driven insights. preferred qualifications: project experience: demonstrated experience in projects such as business performance analysis, sentiment analysis, fraud detection, and waste image classification. certifications: relevant certifications in generative ai, large language models, advanced learning algorithms, and data analysis. what we offer: a collaborative and innovative work environment. opportunities for professional growth and development. the chance to work on cutting - edge projects that drive real - world impact. how to apply: interested candidates should submit their resume and a cover letter detailing their relevant experience and qualifications. applications will be reviewed on a rolling basis. equal opportunity employer: we are an equal opportunity employer and welcome applications from all qualified candidates. we value diversity and are committed to creating an inclusive environment for all employees.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0c82da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T05:55:21.076366Z",
     "start_time": "2024-08-29T05:55:11.990683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Yussuf-Resume.pdf with score 0.7438\n",
      "Rank 2: Taofik CV RPI.pdf with score 0.6710\n",
      "Rank 3: Johanson_Onyegbula_CV.pdf with score 0.6612\n",
      "Rank 4: MUTALIB Tunde Lawal; CV.pdf with score 0.6456\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input_texts = [f\"{cv} [SEP] {new_job[0]}\" for cv in new_cvs]\n",
    "tokenized_inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Get model predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_inputs)\n",
    "    predictions = torch.softmax(outputs.logits, dim=1)[:, 1]  # Probability of being relevant\n",
    "\n",
    "# Rank CVs based on predictions\n",
    "ranked_cvs = sorted(zip(new_cvs.keys(), predictions.numpy()), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Output ranked CVs\n",
    "for i, (cv, score) in enumerate(ranked_cvs):\n",
    "    print(f\"Rank {i+1}: {cv} with score {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a4b08",
   "metadata": {},
   "source": [
    "# Generating Summary for each CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c67ccfb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T01:17:40.273031Z",
     "start_time": "2024-08-30T01:17:34.483843Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def summarize_text(text):\n",
    "    summary = summarizer(text, max_length=200, min_length=50, do_sample=False)\n",
    "    return summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5377765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T01:51:27.525737Z",
     "start_time": "2024-08-30T01:47:30.414837Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Benjamin_Salebaigi.pdf:\n",
      "CV Summary:\n",
      "Benjamin salebaigi 2011 - 70 temperance street, toronto, on, m5h 4e8 (604) 889 - 2622; benjaminsalebaigi@gmail.com; https://www.linkedin.com/in/benjamin-salebaigi/ education johnson graduate school of management, cornell university, ithaca, ny, usa master of international management (mim), applied economics stream (cems) dual degree ivey business school, western university, london,. on, canada january 2022 - may 2023 master of science in management (msc), international business stream. work experience kaseya, vancouver,. canada (\n",
      "\n",
      "Summary for CV Martin Kriletich 2024.pdf:\n",
      "CV Summary:\n",
      " martin kriletich is a global business management professional, with a strong background in business development. martin brings a wealth of experience and a passion for business expansion, coupled with a blend of creative thinking, analytical prowess, and a can - do attitude.\n",
      "\n",
      "Summary for CV Podcast Host_Producer Damien  Swaby  (1).pdf:\n",
      "CV Summary:\n",
      "Damien swaby is a passionate and imaginative podcast producer and host boasting over 4 years of industry experience. He is pro cient in audio/ video/ graphic editing, script writing, content sourcing, social management, music mixing, and talent development.\n",
      "\n",
      "Summary for Kindra Keener 2024 CV.pdf:\n",
      "CV Summary:\n",
      " kindra keener has over 15 years of experience selling professional services. She leads a team of business development and marketing resources to drive growth and revenue development within the portfolio of $20+m sales pipeline. She has a proven track record of developing a trusted advisor relationship with existing clients, producing $2.5+m in revenue per year.\n",
      "\n",
      "Error summarizing text: index out of range in self\n",
      "Summary for Violetta_Nadbitova_CV-1.pdf:\n",
      "CV Summary:\n",
      "violetta nadbitova 07725003082 | venadbitova@gmail.com | https://www.linkedin.com/in/violettanadbitova/ | no visa sponsorship required | salford, united kingdom | immediate availability | geographically mobile personal statement i am developing my career in multimedia and have a diverse international background. i have gained experience in multimedia journalism through my work with an english - speaking newspaper in russia. i am motivated by hard work and find inspiration in people and their stories. my passion lies in exploring new avenues and gaining firsthand experience in the field of multimedia. drawing from my diverse background and previous experiences living and working in various countries, i have launched my own podcast called \"diversity podcast.\" key skills functional expertise: research, storytelling, video production, journalism, content creation, editing, copywriting, interview, radio production, cross - cultural communication, community outreach, bilingual (english, russian), reportage, video and photo editing. technical skills: microsoft office / sharepoint, consultant plus, adobe creative cloud: premiere pro, audition and photoshop, reaper. education ma in international journalism - liverpool john moores university liverpool, uk 2017 2018 modules studied: journalism studies, broadcast journalism, advanced uk broadcast journalism. bs in social sciences - national research university higher school of economics, moscow, russia 2012 2017. hidden employment in provinces national research university, uryupinsk, russia. apr 2017 research focused on the shadow economy sector, specifically self - employment in the natural resources sector. a - levels: 5 passes at a - b elista multidisciplinary gymnasium, russia 2001 2012 professional experience podcaster may 2023 - present - diversity podcast. i single - handedly create, edit, and produce my podcast titled \"diversity podcast.\" this show delves into the subjects of diversity and emphasises the significance of embracing one's identity. work experience feb 2023 - feb 2023 nine lives media salford, mediacityuk, uk editor oct 2022 - present ready - visa, london, uk - remote editing global talent visa case documents helping with the required documents preparation for visa managing and editing content freelance photographer mar 2018 present violettanadbitova.com collaborating with different subjects from all walks of life and different age groups, including working with different social groups to lead photography / videography work for personal projects and clients working with various teams to ensure the subject is prepared for the shoot and that the lighting is correct utilizing photographic best practices to capture both action shots that convey the emotion in human subjects european customer service advisor apr 2021 nov 2022 bet365 stoke - on - trent, uk brought into the customer team to deliver the highest levels of customer service to a russian and english speaking customer base, performing a range of different customer service tasks thriving in this fast - paced environment and collaborating with different teams to resolve customer issues ensuring all activities comply with best practices, processes, and procedures developing key relationships across the customer portfolio that are based on trust and geared for longevity editorial and marketing assistant jan 2021 mar 2021 alt a review - london - uk supported the creation and publishing of content that resonated with target audiences maintaining tight editorial control of content on various pages edited video and photographic output for distribution across alt a s social media presence delivered professional customer service to site subscribers that was based on trust, honesty, and respect social media manager jan 2020 - apr 2020 mipt, laboratory for it education development - moscow - russia maximised reach and user engagement through developing engaging social media content, including writing daily news and posts that resonated with target audiences infused powerful messaging across social media channels as well as leading multi - platform awareness campaigns multimedia trainee may 2019 nov 2019 the moscow times moscow - moscow - russia brought into the multimedia team at russia s leading english - language newspaper to produce visual content for national and international audiences collaborated with the team on daily news production as well as creating photo and video reportages ensuring all output aligned with editorial policy and quality standards developed fresh angles to ensure that all contributions and content remained compelling, useful and innovative worked to tight deadlines to conceptualise and write features that met the needs of target audiences languages nationality: russian. languages: russian (native); english (professional proficiency); french (a1) professional development reform radio - radio course, march 2023. produced and contributed to the live radio show - your life and mine nistratovschool - 10+10. contemporary documentary photography and visual narrative nov 2022 - feb 23 matt black: the documentary commitment magnum learn mar 2022 localization essentials udacity aug 2020 tesol certificate international open academy apr 2019 boris nemtsov foundation for freedom - boris nemtsov school of journalism and cultural studies, prague, cr jul 2018 aug 2018 volunteering media marketing manager starseed learning, uk mar 2021 - august 2021 volunteer center for curative pedagogics, moscow, mar 2017 - aug 2017 english tutor adaptation and learning center for refugee children, moscow, russia apr 2016 jan 2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def summarize_text(text):\n",
    "    try:\n",
    "        # Check if the text is too long and truncate if necessary\n",
    "        max_length = 1024  # Max token length for BART\n",
    "        if len(text.split()) > max_length:\n",
    "            text = ' '.join(text.split()[:max_length])  # Truncate to max_length tokens\n",
    "\n",
    "        summary = summarizer(text, max_length=150, min_length=50, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing text: {e}\")\n",
    "        return text  # Return original text if summarization fails\n",
    "\n",
    "def extract_relevant_paragraphs(cv_text, job_description_text):\n",
    "    # Tokenize and vectorize the texts\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([cv_text, job_description_text])\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarity_matrix = cosine_similarity(vectors)\n",
    "    return similarity_matrix[0, 1]\n",
    "\n",
    "def generate_summary(cv_text, job_description_text):\n",
    "    # Summarize the CV and Job Description\n",
    "    cv_summary = summarize_text(cv_text)\n",
    "    job_summary = summarize_text(job_description_text)\n",
    "    \n",
    "    # Compare the summaries\n",
    "    extract_relevant_paragraphs(cv_summary, job_summary)\n",
    "    \n",
    "    return cv_summary\n",
    "\n",
    "for cv_name, cv_text in transformed_cvs.items():\n",
    "    cv_summary = generate_summary(cv_text, transformed_job[0])\n",
    "    print(f\"Summary for {cv_name}:\")\n",
    "    print(f\"CV Summary:\\n{cv_summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5380b21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T02:43:08.397975Z",
     "start_time": "2024-08-30T02:40:56.123054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Benjamin_Salebaigi.pdf:\n",
      "CV Summary:\n",
      "Benjamin salebaigi 2011 - 70 temperance street, toronto, on, m5h 4e8 (604) 889 - 2622; benjaminsalebaigi@gmail.com; http://www.linkedin.com/in/benjamin-salebaigi/ education johnson graduate school of management, cornell university, ithaca, ny, usa master of international management (mim), applied economics stream (cems) dual degree ivey business school, western university, london, on,. on, canada (msc) master of science in management (msc), international business stream dual degree . work experience kaseya, vancouver (on - site) may 2023 - jan 2024 account manager quota carrying account managers datto pod (full - time) managed a diverse book of business, providing tailored it efficiency consulting, business reviews, and strategies to drive revenue growth and client retainment for managed service providers (msps)\n",
      "\n",
      "Summary for CV Martin Kriletich 2024.pdf:\n",
      "CV Summary:\n",
      "martin martin kriletich is a global business management professional, with a strong background in business development . martin brings a wealth of experience and a passion for business expansion, coupled with a blend of creative thinking, analytical prowess, and a can - do attitude to discover new ways of fostering demand for products and services, and enabling business growth .\n",
      "\n",
      "i was responsible for prospecting, data orchestration, setting up discovery calls, and helping move sales opportunities through the pipeline. i got the fastest promotion for a bdr in k+c s history.\n",
      "\n",
      "Summary for CV Podcast Host_Producer Damien  Swaby  (1).pdf:\n",
      "CV Summary:\n",
      "Damien swaby is a passionate and imaginative podcast producer and host boasting over 4 years of industry experience . He is a pro cient in audio/ video/ graphic editing, script writing, content sourcing, social management, music mixing, and talent development .\n",
      "\n",
      "07984921407 lmmakerswaby@hotmail.com london, n13, england adobe creative cloud photoshop video cameras english . i am proud to be dependable, eager, and wholeheartedly devoted to any role taken on.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Kindra Keener 2024 CV.pdf:\n",
      "CV Summary:\n",
      "kindra keener has over 15 years of success selling professional services . Lead internal and external relationship building activities with basis vectors founders, global saas client engagement team of business development and marketing resources to drive growth and revenue development within the portfolio of $20+m sales pipeline .\n",
      "\n",
      "manage client relationships to support and drive the execution of acquisition and growth strategy. oversee business development budgets, ensuring timely and accurate resources to achieve strategic revenue objectives support the post - close integration of new acquisitions and organic growth initiatives.\n",
      "\n",
      "Error summarizing text: index out of range in self\n",
      "Summary for Violetta_Nadbitova_CV-1.pdf:\n",
      "CV Summary:\n",
      "violetta nadbitova 07725003082 | venadbitova@gmail.com | https://www.linkedin.com/in/violettanadbitova/ | no visa sponsorship required | salford, united kingdom | immediate availability | geographically mobile personal statement i am developing my career in multimedia and have a diverse international background. i have gained experience in multimedia journalism through my work with an english - speaking newspaper in russia.\n",
      "\n",
      "i am motivated by hard work and find inspiration in people and their stories. my passion lies in exploring new avenues and gaining firsthand experience in the field of multimedia.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "# Load a pre-trained summarization model\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "def summarize_text(text, max_length=500, min_length=200):\n",
    "    \"\"\"Generate a summary of the provided text with adjustable length parameters.\"\"\"\n",
    "    try:\n",
    "        summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing text: {e}\")\n",
    "        return text\n",
    "\n",
    "def extract_sentences(summary_text, num_sentences=4):\n",
    "    \"\"\"Extract a specific number of sentences from the summary text.\"\"\"\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', summary_text.strip())\n",
    "    # Ensure we get at least num_sentences\n",
    "    if len(sentences) < num_sentences:\n",
    "        return sentences\n",
    "    return sentences[:num_sentences]\n",
    "\n",
    "def format_summary(summary_text):\n",
    "    \"\"\"Format the summary into two paragraphs with at least two sentences each.\"\"\"\n",
    "    sentences = extract_sentences(summary_text)\n",
    "    \n",
    "    # Ensure there are at least 4 sentences\n",
    "    if len(sentences) < 4:\n",
    "        return summary_text.strip()\n",
    "    \n",
    "    # Combine sentences into two paragraphs\n",
    "    first_paragraph = ' '.join(sentences[:2])\n",
    "    second_paragraph = ' '.join(sentences[2:])\n",
    "    \n",
    "    return f\"{first_paragraph}\\n\\n{second_paragraph}\"\n",
    "\n",
    "def process_cvs(cvs_texts):\n",
    "    \"\"\"Generate and print two-paragraph summaries for each CV.\"\"\"\n",
    "    for cv_name, cv_text in cvs_texts.items():\n",
    "        summary = summarize_text(cv_text)\n",
    "        formatted_summary = format_summary(summary)\n",
    "        print(f\"Summary for {cv_name}:\")\n",
    "        print(f\"CV Summary:\\n{formatted_summary}\\n\")\n",
    "\n",
    "process_cvs(transformed_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52b23522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T02:59:25.558821Z",
     "start_time": "2024-08-30T02:54:03.483293Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Your max_length is set to 150, but your input_length is only 40. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n",
      "Your max_length is set to 150, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 150, but your input_length is only 47. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\n",
      "Your max_length is set to 150, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "Your max_length is set to 150, but your input_length is only 109. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Benjamin_Salebaigi.pdf:\n",
      "Benjamin salebaigi 2011 - 70 temperance street, toronto, on, m5h 4e8 (604) 889 - 2622; benjaminsalebaigi@gmail.com. education johnson graduate school of management, cornell university, ithaca, ny, usa master of international management (mim), applied economics stream (cems) dual degree ivey business school, western university, london.\n",
      "\n",
      "kaseya, vancouver, canada (on - site) may 2023 - jan 2024 account manager quota carrying account managers datto pod (full - time) managed a diverse book of business. leveraged linkedin to multi - thread within partner s companies to have multiple champions within the org.\n",
      "\n",
      "Summary for CV Martin Kriletich 2024.pdf:\n",
      " martin kriletich global business manager work experience 2023 - 2024. kin + carta | buenos aires partner development manager responsible for building and maintaining relationships with our mach partners.\n",
      "\n",
      "martin martin kriletich is a global business management professional. He has a strong background in rugby equipment and business development.\n",
      "\n",
      "Summary for CV Podcast Host_Producer Damien  Swaby  (1).pdf:\n",
      "Damien swaby is a passionate and imaginative podcast producer and host boasting over 4 years of industry experience. He is known for being dependable, eager, and wholeheartedly devoted to any role taken on.\n",
      "\n",
      "i takew on various responsibilities such as production management, scheduling, audio engineering, promotion, and providing essential guidance. i supply and oversee the voice - over pipeline.\n",
      "\n",
      "Summary for Kindra Keener 2024 CV.pdf:\n",
      " kindra keener professional experience lead internal and external relationship building activities. basis vectors founders, global saas client engagement team of business development and marketing resources to drive growth and revenue development.\n",
      "\n",
      "developing strategic partnerships and closing sales opportunities, winning new regional and global business. Leaded a clear process and structure of a high performing business development team.\n",
      "\n",
      "Summary for Violetta_Nadbitova_CV-1.pdf:\n",
      " violetta nadbitova 07725003082 | venadbitva@gmail.com | no visa sponsorship required | salford, united kingdom | immediate availability | geographically mobile personal statement i am developing my career in multimedia and have a diverse international background. i have gained experience in multimedia journalism through my work with an english - speaking newspaper in russia.\n",
      "\n",
      "i am motivated by hard work and find inspiration in people and their stories. i single - handedly create, edit, and produce my podcast titled \"diversity podcast\" this show delves into the subjects of diversity and emphasises the significance of embracing one's identity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import re\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def summarize_text(text):\n",
    "    # Handle long text by chunking\n",
    "    max_chunk_size = 1024\n",
    "    text_chunks = [text[i:i + max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n",
    "\n",
    "    summary_parts = []\n",
    "    for chunk in text_chunks:\n",
    "        try:\n",
    "            summary = summarizer(chunk, max_length=150, min_length=30, do_sample=False)[0]['summary_text']\n",
    "            summary_parts.append(summary)\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing text: {e}\")\n",
    "\n",
    "    return \" \".join(summary_parts)\n",
    "\n",
    "def create_cv_summary(cv_text):\n",
    "    try:\n",
    "        # Summarize text\n",
    "        summary = summarize_text(cv_text)\n",
    "\n",
    "        # Split summary into sentences\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', summary)\n",
    "        \n",
    "        # Ensure at least 4 sentences are used\n",
    "        if len(sentences) < 4:\n",
    "            sentences += [''] * (4 - len(sentences))\n",
    "        \n",
    "        # Create paragraphs\n",
    "        para1 = ' '.join(sentences[:2])\n",
    "        para2 = ' '.join(sentences[2:4])\n",
    "\n",
    "        return f\"{para1}\\n\\n{para2}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CV: {e}\")\n",
    "        return \"Error processing CV.\"\n",
    "\n",
    "def summarize_cv_dict(cv_dict):\n",
    "    summaries = {}\n",
    "    for name, text in cv_dict.items():\n",
    "        summaries[name] = create_cv_summary(text)\n",
    "    return summaries\n",
    "\n",
    "\n",
    "summaries = summarize_cv_dict(transformed_cvs)\n",
    "for name, summary in summaries.items():\n",
    "    print(f\"Summary for {name}:\\n{summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
